# Reshaping and summarizing raw data into a tidy data set
In this project I will get data collected from accelerometers from the Samsung Galaxy S smartphone, to transform it, clean it, reshape it, summarize it, in order to generate a tidy data set which can be used for later analysis.  
The raw data is located in this URL: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip. A full description of the data is available at the site where the data was obtained: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones.  
The process to generate the tidy data set from the raw data will be performed by a single script: run_analysis.R. Details on how to operate with it are below.  
Along with this README.md file and the run_analysis.R script, you can find a CodeBook.md file with the description of the variables in the same GitHub location folder.  


## How to operate the run_analysis.R script and generate the tidy data set
To run the run_analysis.R script from your R console, make sure the following conditions are met:  
* The run_analysis.R script is in your working directory
* You have previously downloaded the raw data from its URL and unzipped it into a "UCI HAR Dataset" folder
* Your working directory contains that "UCI HAR Dataset" folder
* The following packages are loaded in your R session: "reshape2" and "dplyr"
Then source the script with a command like this: `source("./run_analysis.R")`.  
Please **allow ~40 seconds for the script to finish**.  
After the script has finished, a new file tidy.txt will available in your working directory.  


## How to load the tidy data set (tidy.txt) into R
You can use either the tidy.txt file generated by the run_analysis.R script or the version downloaded from the Course Project page.  
This is the command you can execute, assuming the tidy.txt file is in your working directory: `read.table("./tidy.txt", header = TRUE)`.  


## How the run_analysis.R script works
Using the raw data located in the "./UCI HAR Dataset/" folder, the script performs the following operations:  

1.  Merges the training and the test sets to create one data set.  
To clip all data together, without any column and row references in the raw data, I had to put all pieces together in the only reasonable way based on the dimensions of the raw data sets. A graphical explanation of this "puzzel" can be found in this diagram, courtesy of David Hood: ![Diagram](https://coursera-forum-screenshots.s3.amazonaws.com/ab/a2776024af11e4a69d5576f8bc8459/Slide2.png)  
2.  Extracts only the measurements on the mean and standard deviation for each measurement.  
3.  Uses descriptive activity names to name the activities in the data set.  
4.  Appropriately labels the data set with descriptive variable names.  
5.  From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.  
6.  Write tidy data set into tidy.txt file.  


1. Item 1
2. Item 2
3. Item 3
    + Item 3a
    + Item 3b

## References
During the process of building the script and preparing the tidy data I consulted the following resources for help:  
* Hadley Wickham's Tiday data [paper](http://vita.had.co.nz/papers/tidy-data.pdf)  
* David Hood's Course Project [FAQ](https://class.coursera.org/getdata-007/forum/thread?thread_id=49)  
* David Hood's Long Data, Wide Data, and Tidy Data [discussion](https://class.coursera.org/getdata-007/forum/thread?thread_id=214)  